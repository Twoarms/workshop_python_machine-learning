{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_image.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Twoarms/workshop_python_machine-learning/blob/master/Parcours/2_Machine_Learning/classification_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fefd_czxpA07",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installation et import des dépendances"
      ]
    },
    {
      "metadata": {
        "id": "5EolJsiUUbpI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous allons utiliser, entre autre, TensorFlow Datasets, une API qui va nous permettre de télécharger et d'utiliser des ensembles de données (datasets) échantillons qu'elle met à disposition."
      ]
    },
    {
      "metadata": {
        "id": "I4A7APH5WF00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Installation de TensorFlow Datasets sur la VM\n",
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RbLvYE-NWWAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compatibilité\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "#TensorFlow et TensorFlow Datasets\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfd\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "#Helper libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Améliorer affichage barre de progression\n",
        "import tqdm\n",
        "import tqdm.auto\n",
        "tqdm.tqdm = tqdm.auto.tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qM7rLyodY98T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST"
      ]
    },
    {
      "metadata": {
        "id": "WKkrL__kZDri",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A l'origine, il y a le dataset MNIST, un jeu de donnée contenant des chiffres de 0 à 9 écrits à la main et qui est souvent le tout premier projet lorsqu'on s'initie au ML. Le Fashion MNIST a été créé pour apporter un problème légèrement plus compliqué que le MNIST classique, qui permet d'obtenir de \"trop\" bons résultats.\n",
        "\n",
        "Ce dataset contient 70 000 images en niveaux de gris et de basse résolution(28*28 pixels). Il est découpé en 10 catégories de vêtements, et chaque image montre 1 article appartenant à une de ces 10 catégories.\n",
        "\n",
        "Tout comme le MNIST classique, il a 60 000 images d'entrainement et 10 000 images de test. Ca peut paraître énorme mais ce sont des ensembles relativement petits qui sont utilisés pour vérifier qu'un algorithme fonctionne tel qu'attendu, ce qui en font des bons points de départs.\n",
        "\n",
        "Le Fashion MNIST est accessible avec TensorFlow Datasets :"
      ]
    },
    {
      "metadata": {
        "id": "koREHhCqfmyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset, metadata = tfd.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S5-ubzsAgo-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Si on doit représenter les images en termes de données, ce sont des tableaux bi-dimensionnels(28 * 28 pixels), la valeur de chaque pixel est comprise entre ```[0 et 255]``` (Car niveau de gris, si c'était du rgb, on aurait entre ```[0 et 255, 0 et 255, 0 et 255]```).\n",
        "\n",
        "Les labels sont une liste d'integer de 0 à 9 correspondant aux classes que nous allons enregister, dans l'ordre, avec le code suivant car elles ne sont pas incluses dans le set."
      ]
    },
    {
      "metadata": {
        "id": "WuWJZ_OVo0Xt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = ['T-shirt/top', 'Pantalon', 'Pull', 'Robe', 'Manteau', 'Sandales', 'Chemise',\n",
        "           'Baskets', 'Sac', 'Bottines']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2LwsnnVpKDC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Afficher la répartion des données"
      ]
    },
    {
      "metadata": {
        "id": "FZaIaXKqptuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "number_train_examples = metadata.splits['train'].num_examples\n",
        "number_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Nombre d'exemples d'entrainement: {}\".format(number_train_examples))\n",
        "print(\"Nombre d'exemples de test: {}\".format(number_test_examples))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3vzJJx0rpr-S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous avons bien 60 000 exemples d'entrainement et 10 000 exemples de test.\n",
        "\n",
        "Rappel : un exemple est une paire \"input-output attendu\", ou \"feature-label\""
      ]
    },
    {
      "metadata": {
        "id": "hhOehgX5q--C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pré-traitement des données"
      ]
    },
    {
      "metadata": {
        "id": "gqn4AKd5rIoy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La valeur de chaque pixel est comprise entre 0 et 255, mais pour que notre modèle fonctionne correctement, cette valeur doit être comprise entre 0 et 1, nous allons donc créer une fonction et l'appliquer sur chacune des images pour convertir cette valeur."
      ]
    },
    {
      "metadata": {
        "id": "RtTC1ceiqtfc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "  return image, label\n",
        "\n",
        "train_dataset = train_dataset.map(convert)\n",
        "test_dataset = test_dataset.map(convert)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UWiLg7Igwm_6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "6HKkAU4PwrI_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Vérification du traitement des données"
      ]
    },
    {
      "metadata": {
        "id": "XUIkcYXFw0Bg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prendre une image, enlever la dimension couleur\n",
        "for image, label in test_dataset.take(1):\n",
        "  break\n",
        "image = image.numpy().reshape((28,28))\n",
        "\n",
        "# Tracer l'image\n",
        "plt.figure()\n",
        "plt.imshow(image, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nc0fOfNEx3uw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Et voilà à quoi ressemble une image !"
      ]
    },
    {
      "metadata": {
        "id": "OjkdV_qVyABX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous allons maintenant afficher les 20 premières images du set d'entrainement et afficher la classe correspondante sous chaque image.\n",
        "\n",
        "Cela nous permet de vérifier que les données sont correctement formatée et que nous sommes prêts à construire et entrainer notre modèle"
      ]
    },
    {
      "metadata": {
        "id": "I8UAor7tyV-Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "i = 0\n",
        "for (image, label) in test_dataset.take(20):\n",
        "  image = image.numpy().reshape((28,28))\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image, cmap=plt.cm.binary)\n",
        "  plt.xlabel(classes[label])\n",
        "  i += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-sq2RVMw0W-_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Construire le modèle"
      ]
    },
    {
      "metadata": {
        "id": "zANWlyzO0cMW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Préparer les couches et le modèle"
      ]
    },
    {
      "metadata": {
        "id": "Pekz1NQf0l2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_WXZ_YiW1DiH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous avons ici 3 couches:\n",
        "1. Input layer : ```tf.keras.layers.Flatten``` - Cette couche nous permet de transformer les images qui sont des tableaux bi-dimensionnels en tableaux uni-dimensionnels. Nous avons donc un tableau de 784 (28*28) pixels au lieu d'un tableau de 28 tableaux de 28 pixels. Cette couche ne sert qu'à transformer les données.\n",
        "2. \"Hidden\" layer : ```tf.keras.layers.Dense``` - Cette couche est \"Fully Connected\"* et possède 256 noeuds/neurones. Chaque neurone prend donc 1 input (chaque pixel a une seule valeur) de chacun des 784 noeuds de la couche précédente, exécute des calculs sur ces inputs fonction du poids et du biais cachés qui seront appris lors de l'entrainement et donne en output une seule valeur qui sera utilisé. \n",
        "3. Output layer : ```tf.keras.layers.Dense``` - Cette dernière couche possède 10 noeuds qui correspondent chacun à une de nos classes, chacun des 10 noeuds prend 1 input de chacun des 256 noeuds de la couche précédente, effectue les calculs avec les paramètres appris et donne en output une valeur entre 0 et 1, qui représente la probabilité que l'image appartiennent à la classe correspondante. La somme des valeurs données par chacun des 10 noeuds est donc de 1.\n",
        "\n",
        "Qu'est-ce que [ReLu](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) ? Grosso modo, il retourne 0 si une valeur est négative, sinon il retourne simplement la valeur. Cela permet de mieux capturer les effets d'interaction et les effets non-linéaires\n",
        "\n",
        "Qu'est-ce que [Softmax](https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax?hl=fr) ? Grosso modo, c'est ce qui nous permet d'avoir les probabilités qu'une image appartienne à chacune des classes pour un total de 1"
      ]
    },
    {
      "metadata": {
        "id": "-ZKKLyT77nAd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compiler le modèle"
      ]
    },
    {
      "metadata": {
        "id": "sRf0TbiG7yX0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Rappel : avant de pouvoir entrainer notre modèle, il faut le compiler et lui ajouter quelques paramètres : la fonction perte, l'optimiseur et ici nous rajoutons un paramètre de mesure qui nous permet de surveiller les étapes d'entrainement et de test. ici nous utilisons ```accuracy```, la proportion d'image correctement classifiée"
      ]
    },
    {
      "metadata": {
        "id": "e5mXF_2R9nnr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4hwYac1TSlen",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Entrainer le modèle"
      ]
    },
    {
      "metadata": {
        "id": "cflqBVRISn1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "D'abord, nous déterminons l'iteration pour l'ensemble de données d'entrainement.\n",
        "\n",
        "Nous disons à notre modèle d'utiliser des lots de 32 images, cela va influer sur le nombre d'iterations par Epoch.\n",
        "\n",
        "Rappel : Une Epoch correspond à un cycle complet ( = Toutes les données sont passées au travers du réseau neuronal. Mais puisque notre set de données est trop trop grand pour être passé au travers du réseau en une fois, nous le découpons en lots de données)\n",
        "\n",
        "```dataset.repeat()``` permet d'itérer \"sans fin\". (C'est le nombre d'Epoch qui va déterminer au final combien de temps l'entrainement va durer)\n",
        "\n",
        "```dataset.shuffle(number_train_examples)``` randomise l'ordre des données pour que le modèle ne puisse rien apprendre de l'ordre dans lequel les données lui sont fournies. (Lui fournir les données toujours dans le même ordre l'induirait en erreur par effet mémoire)\n",
        "\n",
        "```dataset.batch(BATCH_SIZE)``` dit simplement à la méthode ```fit``` (la méthode appelée pour entrainer le modèle) d'utiliser des batches de 32 (tel que défini au début du code)"
      ]
    },
    {
      "metadata": {
        "id": "OXYAMUQV-Q02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.repeat().shuffle(number_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Me8dFSrfXr9b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous appelons ensuite la méthode ```fit``` en lui disant d'utiliser le set d'entrainement et nous définissons le nombre d'Epochs à 5 (ce qui nous donne 5 * 60 000 = 300 000 exemples pour s'entrainer).\n",
        "\n",
        "La perte et la précision sont affichées au fur et à mesure de l'entrainement, avec une précision finale d'environ 90% sur nos données d'entrainement"
      ]
    },
    {
      "metadata": {
        "id": "a-spB2nA-aIt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(number_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCqvRqKZYm4i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tester la précision"
      ]
    },
    {
      "metadata": {
        "id": "2RG1lJWZZnb5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il est maintenant temps de voir comment notre modèle performe sur les données test. Nous allons donc l'évaluer sur la totalité de nos exemples de test"
      ]
    },
    {
      "metadata": {
        "id": "3LL1Axnd_MlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(number_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QyQOch5rbKsR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous remarquons une précision un peu plus faible sur nos données test mais c'est tout a fait normal puisque notre modèle n'avait jamais été confronté à ces données, et cela rend sa précision d'autant plus impressionnante."
      ]
    },
    {
      "metadata": {
        "id": "5V8IE5vJcew4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prédictions"
      ]
    },
    {
      "metadata": {
        "id": "kfPbPwHscgZQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Maintenant que notre modèle est entrainé et que nous avons évalué sa précision sur des données pour lesquelles il n'a pas été entrainé, il est venu le temps de faire des prédictions."
      ]
    },
    {
      "metadata": {
        "id": "ip1PlVEVbLpY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for test_images, test_labels in test_dataset.take(1):\n",
        "  test_images = test_images.numpy()\n",
        "  test_labels = test_labels.numpy()\n",
        "  predictions = model.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YFXqwrWSdIA4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S2Wv_0u2fsIA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous avons 32 prédictions car nous avons défini plus haut que test_dataset était constitué de lots(batches) de 32 images et nous prenons 1 éléments de test_dataset : ```test_dataset.take(1)```\n",
        "\n",
        "Chaque prédiction est constituée de 10 valeurs : la probabilité pour chaque classe de vêtement que notre image en fasse partie."
      ]
    },
    {
      "metadata": {
        "id": "YukeWBHSdPeE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJ-vaXwleYE-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Une prediction est un tableau de 10 nombres. Ces nombres correspondent à la certitude du modèle, la probabilité qu'une image correspond à chacune des 10 classes de vêtement (selon notre modèle). \n",
        "\n",
        "Nous pouvons voir de manière plus simple quelle classe a la plus grande probabilté avec le code suivant:"
      ]
    },
    {
      "metadata": {
        "id": "BQlVSOWvezZR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R8f6r5PhfLEX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notre modèle pense donc que notre image appartient à la classe 6, autrement dit : Chemise.\n",
        "\n",
        "Vérifions cela :"
      ]
    },
    {
      "metadata": {
        "id": "A38s7-MgfWcg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udmzENgLgjMX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Réprésentons graphiquement l'ensemble des 10 valeurs."
      ]
    },
    {
      "metadata": {
        "id": "-uC7wtOlh9eO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "D'abord nous définissons nos fonctions qui vont nous permettre cela"
      ]
    },
    {
      "metadata": {
        "id": "GKezgD32hUTW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_labels, images):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(classes[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                classes[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1]) \n",
        "  predicted_label = np.argmax(predictions_array)\n",
        " \n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xU4leu0eiFg2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Maintenant regardons notre première image (index 0)"
      ]
    },
    {
      "metadata": {
        "id": "A6DhKLzniKUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y2Loa3Iaiy9t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notre 13eme image (index 12)"
      ]
    },
    {
      "metadata": {
        "id": "HoCR3Hf9idQT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CmoQa6o6qsds",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Représentons plusieurs images et leurs prédictions, le pourcentage affiché correspond à la certitude de notre modèle sur sa prédiction. Il est important de noter que le modèle peut se tromper, même avec un haut de niveau de certitude."
      ]
    },
    {
      "metadata": {
        "id": "sWg85KKyjN-t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Représenter les 15 premières images test, le label prédit et le label attendu\n",
        "# La couleur bleue représente le label attendu, la couleur rouge le label prédit\n",
        "# lorsqu'il ne correspond pas au label attendu\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aj6Eaqs0rfys",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Enfin, utilisons notre modèle pour une prédiction sur une seule image et analyser le résultat en détail. Reprenons pour ça notre première image (index 0), celle d'une chemise et"
      ]
    },
    {
      "metadata": {
        "id": "zFt4nWEoroFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = test_images[0]\n",
        "print(image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ty8CtyxXrzaj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Les modèles construits avec ```tf.keras``` sont optimisés pour des prédictions sur des lots, nous allons donc créer un \"lot\" d'une seule image"
      ]
    },
    {
      "metadata": {
        "id": "AcZFa4sesFg6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = np.array([image])\n",
        "print(image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjTJS09at11i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unique_prediction = model.predict(image)\n",
        "print(unique_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sh5kaXost9x7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_value_array(0, unique_prediction, test_labels)\n",
        "\n",
        "_ = plt.xticks(range(10), classes, rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYhTZ2Wywugx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```model.predict``` retourne une liste de liste, une pour chaque image de notre lot (ici composé d'une seule image). Récupérons la prédiction :"
      ]
    },
    {
      "metadata": {
        "id": "qna0WHdhxJVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.argmax(unique_prediction[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TeMNLqA3xRY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Comme avant, nous avons bien le label 6 (chemise)"
      ]
    },
    {
      "metadata": {
        "id": "Z8_YuTmUxaNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Et voilà, n'hésitez pas à\n",
        " - Jouer avec le nombre d'Epochs\n",
        " - Changer le nombre de neurones dans notre \"Hidden layer\"\n",
        " - Rajouter des \"Hidden layers\" composées de différents nombres de neurones entre la couche ```Flatten``` et la couche ```Dense``` finale (celle avec activation=tf.nn.softmax)\n",
        " \n",
        "pour expérimenter un peu et obtenir des résultats différents"
      ]
    }
  ]
}